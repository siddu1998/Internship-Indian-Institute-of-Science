{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment to determine Frequency for running Model \n",
    "\n",
    "Author : Sai Siddartha Maram\n",
    "\n",
    "\n",
    "Contact: msaisiddartha1@gmail.com | smaram_be16@thapar.edu\n",
    "\n",
    "### Objectives\n",
    "1. Run detection at Camera FPS, in our case the camera FPS is 30FPS, to start of I will run detection on every 30th image.\n",
    "2. Log all the bounding boxes and classes of objects detected\n",
    "3. Develop a certain metric in terms of centers of bounding boxes, classes detected to determine if the two scenes are different\n",
    "4. Try delta methods and see if they match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import imutils\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "import numpy as np\n",
    "\n",
    "from skimage.measure import compare_ssim\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "import scipy\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "# Image manipulation.\n",
    "from PIL import Image\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import inception5h\n",
    "model = inception5h.Inception5h()\n",
    "\n",
    "import imagehash\n",
    "# My Packages\n",
    "import constants\n",
    "import helper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Model : YOLOV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Inception 5h Model ...\n",
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "options = constants.options_v3\n",
    "np.random.seed(42)\n",
    "LABELS = open(options['labelsPath']).read().strip().split(\"\\n\")\n",
    "color = (255, 0, 0)\n",
    "inception5h.maybe_download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load the darknet model using readNetFromDarkent(), feel free to try other DL models\n",
    "2.  In CV2.dnn you load a model and then forward propgate the image for prediction, \n",
    "    the forwad function expects you give the layer till which you want the image to be \n",
    "    propgated, in our case since we want the final result, we want the image to be \n",
    "    propgated till the last layer. The .getLayerNames() gives the list of all layers.\n",
    "    From here to identify the last layer, we need to get last unconnected layer, the \n",
    "    unconnected layers can be found by .getUnconnectedOutLayers().\n",
    "3. blob, the cv.dnn does not take a raw image, instead takes a blob, A blob is an image which \n",
    "   is modified and smoothed as per the network requirments. For Ex. \n",
    "   YOLO takes in an image only of the size 416 x 416 (single channel)\n",
    "   hence we reduce each color from [0-255] to [0-1] and image size (416,416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_object(image_path,net):\n",
    "    start = time.time()\n",
    "    image = cv2.imread(image_path)\n",
    "    #image=cv2.resize(image,(416,416))\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    layerOutputs = net.forward(ln)\n",
    "    \n",
    "\n",
    "    # show timing information on YOLO\n",
    "    \n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > options['confidence']:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, options['confidence'], options['threshold'])\n",
    "    \n",
    "    detections=[]\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            temp_list=[]\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            \n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 3)\n",
    "            text = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n",
    "            cv2.putText(image, text, (x, y - 5),cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            plt.imshow(image)\n",
    "\n",
    "            temp_list.append(x)\n",
    "            temp_list.append(y)\n",
    "            temp_list.append(w)\n",
    "            temp_list.append(h)\n",
    "            temp_list.append(LABELS[classIDs[i]])\n",
    "            temp_list.append(confidences[i])\n",
    "            detections.append(temp_list)\n",
    "            \n",
    "    print('Time Taken', time.time()-start)   \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image,net):\n",
    "    start = time.time()\n",
    "    #image = cv2.imread(image_path)\n",
    "    #image=cv2.resize(image,(416,416))\n",
    "    (H, W) = image.shape[:2]\n",
    "\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    layerOutputs = net.forward(ln)\n",
    "    \n",
    "\n",
    "    # show timing information on YOLO\n",
    "    \n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > options['confidence']:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, options['confidence'], options['threshold'])\n",
    "    \n",
    "    detections=[]\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            temp_list=[]\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            \n",
    "            cv2.rectangle(image, (x, y), (x + w, y + h), color, 3)\n",
    "            text = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n",
    "            cv2.putText(image, text, (x, y - 5),cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            plt.imshow(image)\n",
    "\n",
    "            temp_list.append(x)\n",
    "            temp_list.append(y)\n",
    "            temp_list.append(w)\n",
    "            temp_list.append(h)\n",
    "            temp_list.append(LABELS[classIDs[i]])\n",
    "            temp_list.append(confidences[i])\n",
    "            detections.append(temp_list)\n",
    "            \n",
    "    print('Time Taken', time.time()-start)   \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet(options['model'], options['load'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections=predict_object('testing_images/4561.jpg',net)\n",
    "print('Number of Detections:', len(detections))\n",
    "print(*detections,sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections=predict_object('testing_images/16892.jpg',net)\n",
    "print('Number of Detections:', len(detections))\n",
    "print(*detections,sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_subtraction(path_image1,path_image2):\n",
    "    img1 = cv2.imread(path_image1)\n",
    "    img2 = cv2.imread(path_image2)\n",
    "\n",
    "\n",
    "    start_time=time.time()\n",
    "    grayA = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    grayB = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    (score, grad,diff) = compare_ssim(grayA, grayB, full=True,gradient=True)\n",
    "    #value ranges between -1 to 1. 1 indicates a perfect match\n",
    "    print('Time Taken for execution',time.time()-start_time)\n",
    "    print(\"SSIM: {}\".format(score))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_subtraction('testing_images/4561.jpg','testing_images/16892.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_matching(path_image1, path_image2):\n",
    "    img1 = cv2.imread(path_image1)\n",
    "    img2 = cv2.imread(path_image2)\n",
    "#     plt.hist(img1.ravel(),256,[0,256])\n",
    "#     plt.show()\n",
    "#     plt.hist(img2.ravel(),256,[0,256])\n",
    "#     plt.show()\n",
    "\n",
    "    img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "    img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "    start_time=time.time()\n",
    "\n",
    "    hist1 = cv2.calcHist(img1, [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    hist1 = cv2.normalize(hist1, hist1).flatten()\n",
    "\n",
    "    hist2 = cv2.calcHist(img2, [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    hist2 = cv2.normalize(hist2, hist2).flatten()\n",
    "\n",
    "    #a = cv2.compareHist(hist1, hist2, cv2.HISTCMP_INTERSECT) ----> WASTE!\n",
    "    #a = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL) ----->Waste!\n",
    "    chi_square = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CHISQR)\n",
    "    print('[INFO]Time for Histogram Mapping',time.time()-start_time)\n",
    "\n",
    "    return chi_square\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi=histogram_matching('testing_images/4561.jpg','testing_images/4561.jpg')\n",
    "print('CHI Square value',chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi=histogram_matching('testing_images/4561.jpg','testing_images/16892.jpg')\n",
    "print('CHI Square value',chi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi=histogram_matching('testing_images/4561.jpg','testing_images/2.jpg')\n",
    "print('CHI Square value',chi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learnable Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread('testing_images/16892.jpg')\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=8\n",
    "M=8\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b=[]\n",
    "# for x in range(0,img.shape[0],M):\n",
    "#     for y in range(0,img.shape[1],N):\n",
    "#         b.append(img[x:x+M,y:y+N])\n",
    "# print(len(b))\n",
    "\n",
    "blank_image = np. zeros(shape=[1080,1920, 3], dtype=np. uint8)\n",
    "\n",
    "for x in range(0,img.shape[0],M):\n",
    "    for y in range(0,img.shape[1],N):\n",
    "        blank_image[x:x+M,y:y+N]=img[x:x+M,y:y+N]+129\n",
    "\n",
    "cv2.imshow('img',blank_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "plt.imshow(blank_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections=predict_image(blank_image,net)\n",
    "print('Number of Detections:', len(detections))\n",
    "print(*detections,sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look up table for color mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def look_up_table_mapping(im_gray) :\n",
    "    \n",
    "    lut = np.zeros((256, 1, 3), dtype=np.uint8)\n",
    "    lut[:, 0, 0] = [255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,253,251,249,247,245,242,241,238,237,235,233,231,229,227,225,223,221,219,217,215,213,211,209,207,205,203,201,199,197,195,193,191,189,187,185,183,181,179,177,175,173,171,169,167,165,163,161,159,157,155,153,151,149,147,145,143,141,138,136,134,132,131,129,126,125,122,121,118,116,115,113,111,109,107,105,102,100,98,97,94,93,91,89,87,84,83,81,79,77,75,73,70,68,66,64,63,61,59,57,54,52,51,49,47,44,42,40,39,37,34,33,31,29,27,25,22,20,18,17,14,13,11,9,6,4,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    lut[:, 0, 1] = [255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,255,254,252,250,248,246,244,242,240,238,236,234,232,230,228,226,224,222,220,218,216,214,212,210,208,206,204,202,200,198,196,194,192,190,188,186,184,182,180,178,176,174,171,169,167,165,163,161,159,157,155,153,151,149,147,145,143,141,139,137,135,133,131,129,127,125,123,121,119,117,115,113,111,109,107,105,103,101,99,97,95,93,91,89,87,85,83,82,80,78,76,74,72,70,68,66,64,62,60,58,56,54,52,50,48,46,44,42,40,38,36,34,32,30,28,26,24,22,20,18,16,14,12,10,8,6,4,2,0 ]\n",
    "    lut[:, 0, 2] = [195,194,193,191,190,189,188,187,186,185,184,183,182,181,179,178,177,176,175,174,173,172,171,170,169,167,166,165,164,163,162,161,160,159,158,157,155,154,153,152,151,150,149,148,147,146,145,143,142,141,140,139,138,137,136,135,134,133,131,130,129,128,127,126,125,125,125,125,125,125,125,125,125,125,125,125,125,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,127,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126,126]\n",
    "    \n",
    "    \n",
    "    print('image')\n",
    "    print(im_gray[0][0])\n",
    "\n",
    "    print('Look Up Table')\n",
    "    print(lut[:, 0, 0][50])\n",
    "    print(lut[:, 0, 1][58])\n",
    "    print(lut[:, 0, 2][57])\n",
    "    \n",
    "    im_color = cv2.LUT(im_gray, lut)\n",
    "    print('im_color')\n",
    "    print(im_color[0][0])\n",
    "    return im_color;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread('testing_images/sample_dog.jpg' )\n",
    "im_color = look_up_table_mapping(im)\n",
    "\n",
    "cv2.imshow('encoded',im_color)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections=predict_object('testing_images/sample_dog.jpg',net)\n",
    "print('Number of Detections:', len(detections))\n",
    "print(*detections,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections=predict_image(im_color,net)\n",
    "print('Number of Detections:', len(detections))\n",
    "print(*detections,sep='\\n')\n",
    "\n",
    "\n",
    "# detections=predict_object('testing_images/4561.jpg',net)\n",
    "# print('Number of Detections:', len(detections))\n",
    "# print(*detections,sep='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection Performance and Evaluation Based on Image Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
